{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c3a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone YOLOv5 repository\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe93cf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/yolov5\n",
      "HEAD is now at 886f1c0 DDP after autoanchor reorder (#2421)\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5\n",
    "!git reset --hard 886f1c03d839575afecb059accf74296fad395b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe406eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Setup complete. Using torch 1.10.1+cu102 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# install dependencies as necessary\n",
    "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
    "import torch\n",
    "\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "from utils.google_utils import gdrive_download  # to download models/datasets\n",
    "\n",
    "# clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d241a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!curl -L \"https://app.roboflow.com/ds/26xfywUkiO?key=jV7tJHJv2V\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72dbd7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'yolov5/'\n",
      "/home/ec2-user/SageMaker/yolov5\n",
      "train: ../train/images\n",
      "val: ../valid/images\n",
      "\n",
      "nc: 3\n",
      "names: ['0', '1', '2']"
     ]
    }
   ],
   "source": [
    "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
    "%cd yolov5/\n",
    "%cat data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18c8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of classes based on YAML\n",
    "import yaml\n",
    "with open(\"data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3185fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# parameters\n",
      "nc: 80  # number of classes\n",
      "depth_multiple: 1.33  # model depth multiple\n",
      "width_multiple: 1.25  # layer channel multiple\n",
      "\n",
      "# anchors\n",
      "anchors:\n",
      "  - [10,13, 16,30, 33,23]  # P3/8\n",
      "  - [30,61, 62,45, 59,119]  # P4/16\n",
      "  - [116,90, 156,198, 373,326]  # P5/32\n",
      "\n",
      "# YOLOv5 backbone\n",
      "backbone:\n",
      "  # [from, number, module, args]\n",
      "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
      "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
      "   [-1, 3, C3, [128]],\n",
      "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
      "   [-1, 9, C3, [256]],\n",
      "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
      "   [-1, 9, C3, [512]],\n",
      "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
      "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
      "   [-1, 3, C3, [1024, False]],  # 9\n",
      "  ]\n",
      "\n",
      "# YOLOv5 head\n",
      "head:\n",
      "  [[-1, 1, Conv, [512, 1, 1]],\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
      "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
      "   [-1, 3, C3, [512, False]],  # 13\n",
      "\n",
      "   [-1, 1, Conv, [256, 1, 1]],\n",
      "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
      "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
      "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
      "\n",
      "   [-1, 1, Conv, [256, 3, 2]],\n",
      "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
      "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
      "\n",
      "   [-1, 1, Conv, [512, 3, 2]],\n",
      "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
      "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
      "\n",
      "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
      "  ]\n"
     ]
    }
   ],
   "source": [
    "#this is the model configuration we will use for our tutorial \n",
    "%cat ../yolov5/models/yolov5x.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f79e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de08f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate ../yolov5/models/custom_yolov5x.yaml\n",
    "\n",
    "# parameters\n",
    "nc: 3  # number of classes\n",
    "depth_multiple: 1.33  # model depth multiple\n",
    "width_multiple: 1.25  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, C3, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, C3, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, C3, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, C3, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, C3, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e8ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/yolov5\n",
      "remote: Enumerating objects: 6, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 6 (delta 5), reused 5 (delta 5), pack-reused 1\u001b[K\n",
      "Unpacking objects: 100% (6/6), done.\n",
      "From https://github.com/ultralytics/yolov5\n",
      "   84651d8..50a1707  test/conv_reduction -> origin/test/conv_reduction\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 897 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n",
      "YOLOv5 v4.0-126-g886f1c0 torch 1.10.1+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "Namespace(adam=False, batch_size=16, bucket='', cache_images=True, cfg='./models/custom_yolov5x.yaml', data='./data.yaml', device='', entity=None, epochs=100, evolve=False, exist_ok=False, global_rank=-1, hyp='./data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], linear_lr=False, local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='yolov5x_results_0317', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/yolov5x_results_0317', single_cls=False, sync_bn=False, total_batch_size=16, weights='', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
      "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      8800  models.common.Focus                     [3, 80, 3]                    \n",
      "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2                -1  1    309120  models.common.C3                        [160, 160, 4]                 \n",
      "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4                -1  1   3285760  models.common.C3                        [320, 320, 12]                \n",
      "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6                -1  1  13125120  models.common.C3                        [640, 640, 12]                \n",
      "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
      "  8                -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \n",
      "  9                -1  1  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
      " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
      " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1   1335040  models.common.C3                        [640, 320, 4, False]          \n",
      " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1   4922880  models.common.C3                        [640, 640, 4, False]          \n",
      " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
      " 24      [17, 20, 23]  1     53832  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Model Summary: 607 layers, 87257832 parameters, 87257832 gradients, 217.4 GFLOPS\n",
      "\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 134 .bias, 134 conv.weight, 131 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../train/labels' for images and labels... 4001 found, 0 missing\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../train/labels.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (4.9GB): 100%|██████| 4001/4001 [00:02<00:00, 1395.36it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../valid/labels' for images and labels... 579 found, 0 missing, 0\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../valid/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB): 100%|██████████| 579/579 [00:00<00:00, 1551.79it/s]\u001b[0m\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.06, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 640 train, 640 test\n",
      "Using 8 dataloader workers\n",
      "Logging results to runs/train/yolov5x_results_0317\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "      0/99     13.4G   0.06686   0.02653     0.032    0.1254         4       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579     0.00539       0.189     0.00345    0.000461\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "      1/99     13.8G   0.05869   0.02431    0.0297    0.1127         2       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.016       0.428      0.0215     0.00394\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "      2/99     13.8G   0.05396   0.02294   0.02863    0.1055         1       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579      0.0039       0.707     0.00391    0.000481\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "      3/99     13.8G   0.04547   0.01763   0.02555   0.08866         3       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.284       0.643       0.318      0.0771\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "      4/99     13.8G   0.03647    0.0135   0.02346   0.07343         0       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.643       0.978       0.703       0.534\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "      5/99     13.8G   0.02966   0.01083   0.02145   0.06194         2       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.304       0.966       0.504       0.433\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "      6/99     13.8G   0.02587  0.009154   0.02144   0.05646         1       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.665           1       0.775       0.678\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "      7/99     13.8G   0.02428    0.0083   0.02183   0.05441         1       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.978       0.318       0.545       0.489\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "      8/99     13.8G   0.02198  0.007433   0.02015   0.04957         4       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.689       0.976       0.782       0.641\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "      9/99     13.8G   0.02101  0.007325   0.01907    0.0474         4       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579        0.62       0.858       0.787       0.703\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     10/99     13.8G   0.02095  0.007084   0.01583   0.04386         1       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.883       0.891       0.974       0.891\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     11/99     13.8G   0.02148  0.007075   0.01294   0.04149         1       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.975       0.984       0.993       0.909\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     12/99     13.8G   0.01994  0.006992   0.01224   0.03917         2       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.875       0.876       0.983       0.912\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     13/99     13.8G   0.01872  0.006632  0.008507   0.03386         1       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.984       0.972       0.995       0.924\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     14/99     13.8G   0.01923  0.006494  0.008995   0.03472         2       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.999           1       0.995       0.933\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     15/99     13.8G   0.01871  0.006504  0.006861   0.03207         2       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.996       0.973       0.995       0.921\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     16/99     13.8G   0.01857  0.006214  0.007652   0.03244         2       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.878       0.957        0.99       0.941\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     17/99     13.8G   0.01757  0.006008  0.005115   0.02869         4       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.944        0.93       0.995       0.926\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     18/99     13.8G   0.01789   0.00569  0.005396   0.02898         4       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.981       0.993       0.995       0.936\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     19/99     13.8G   0.01662  0.005652  0.004393   0.02666         4       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.999           1       0.995       0.957\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     20/99     13.8G   0.01637   0.00554  0.004278   0.02619         1       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579       0.994       0.993       0.995       0.944\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     21/99     13.8G   0.01602   0.00539  0.004726   0.02614         2       640\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         579         579         0.9       0.825       0.914       0.687\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "     22/99     13.8G   0.01585  0.005352  0.005041   0.02625        28       640"
     ]
    }
   ],
   "source": [
    "# train yolov5s on custom data for 100 epochs\n",
    "# time its performance\n",
    "%cd ../yolov5/\n",
    "!python train.py --img 640 --batch 16 --epochs 100 --data '/data.yaml' --cfg ./models/custom_yolov5x.yaml --weights '' --name yolov5x_results_0317  --cache --hyp '/data/hyp.scratch.yaml' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights best.pt --img 640 --conf 0.5 --source \"圖片路徑\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56472769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033163f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
